2022-07-07 10:12:59,785 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting RestfulWebServiceApplication using Java 17.0.3 on MacBook-Pro-de-Joao-3.local with PID 40252 (/Users/joaosouto/Desktop/projetos/RESTful-Web-Service/target/classes started by joaosouto in /Users/joaosouto/Desktop/projetos/RESTful-Web-Service)
2022-07-07 10:12:59,787 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-07-07 10:12:59,852 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-07-07 10:12:59,852 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-07-07 10:13:00,454 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-07-07 10:13:00,468 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 8 ms. Found 0 Reactive MongoDB repository interfaces.
2022-07-07 10:13:01,803 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-srv-cluster0.e01hz.mongodb.net] Adding discovered server cluster0-shard-00-01.e01hz.mongodb.net:27017 to client view of cluster
2022-07-07 10:13:01,813 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.0"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "12.2"}, "platform": "Java/Eclipse Adoptium/17.0.3+7"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='mindswap123', source='admin', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@70d3f998, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@4ef3d003]}, clusterSettings={hosts=[127.0.0.1:27017], srvHost=cluster0.e01hz.mongodb.net, srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='atlas-13mede-shard-0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=true, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-07-07 10:13:01,829 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-srv-cluster0.e01hz.mongodb.net] Adding discovered server cluster0-shard-00-02.e01hz.mongodb.net:27017 to client view of cluster
2022-07-07 10:13:01,831 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-srv-cluster0.e01hz.mongodb.net] Adding discovered server cluster0-shard-00-00.e01hz.mongodb.net:27017 to client view of cluster
2022-07-07 10:13:02,045 INFO org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] LiveReload server is running on port 35729
2022-07-07 10:13:02,366 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-07 10:13:02,424 WARN org.apache.kafka.clients.ClientUtils [restartedMain] Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
2022-07-07 10:13:02,428 ERROR org.springframework.core.log.LogAccessor [restartedMain] Could not create admin
org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:538)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:143)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:49)
	at org.springframework.kafka.core.KafkaAdmin.createAdmin(KafkaAdmin.java:228)
	at org.springframework.kafka.core.KafkaAdmin.initialize(KafkaAdmin.java:166)
	at org.springframework.kafka.core.KafkaAdmin.afterSingletonsInstantiated(KafkaAdmin.java:145)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:972)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.refresh(ReactiveWebServerApplicationContext.java:66)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at academy.mindswap.restfulwebservice.RestfulWebServiceApplication.main(RestfulWebServiceApplication.java:17)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:490)
	... 20 common frames omitted
2022-07-07 10:13:02,477 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [kafka:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-example-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = example
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-07-07 10:13:02,659 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-cluster0-shard-00-00.e01hz.mongodb.net:27017] Opened connection [connectionId{localValue:5, serverValue:63280}] to cluster0-shard-00-00.e01hz.mongodb.net:27017
2022-07-07 10:13:02,659 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-cluster0-shard-00-01.e01hz.mongodb.net:27017] Opened connection [connectionId{localValue:3, serverValue:62731}] to cluster0-shard-00-01.e01hz.mongodb.net:27017
2022-07-07 10:13:02,659 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-cluster0-shard-00-02.e01hz.mongodb.net:27017] Opened connection [connectionId{localValue:6, serverValue:67500}] to cluster0-shard-00-02.e01hz.mongodb.net:27017
2022-07-07 10:13:02,659 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-cluster0-shard-00-02.e01hz.mongodb.net:27017] Opened connection [connectionId{localValue:4, serverValue:67384}] to cluster0-shard-00-02.e01hz.mongodb.net:27017
2022-07-07 10:13:02,659 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-cluster0-shard-00-00.e01hz.mongodb.net:27017] Opened connection [connectionId{localValue:2, serverValue:63282}] to cluster0-shard-00-00.e01hz.mongodb.net:27017
2022-07-07 10:13:02,659 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-cluster0-shard-00-01.e01hz.mongodb.net:27017] Opened connection [connectionId{localValue:1, serverValue:62731}] to cluster0-shard-00-01.e01hz.mongodb.net:27017
2022-07-07 10:13:02,660 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-cluster0-shard-00-01.e01hz.mongodb.net:27017] Monitor thread successfully connected to server with description ServerDescription{address=cluster0-shard-00-01.e01hz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=371379671, setName='atlas-13mede-shard-0', canonicalAddress=cluster0-shard-00-01.e01hz.mongodb.net:27017, hosts=[cluster0-shard-00-00.e01hz.mongodb.net:27017, cluster0-shard-00-01.e01hz.mongodb.net:27017, cluster0-shard-00-02.e01hz.mongodb.net:27017], passives=[], arbiters=[], primary='cluster0-shard-00-02.e01hz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='GCP'}, Tag{name='region', value='WESTERN_EUROPE'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, topologyVersion=TopologyVersion{processId=62c571b7bfd6009395128625, counter=3}, lastWriteDate=Thu Jul 07 10:13:02 WEST 2022, lastUpdateTimeNanos=31272680643077}
2022-07-07 10:13:02,660 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-cluster0-shard-00-00.e01hz.mongodb.net:27017] Monitor thread successfully connected to server with description ServerDescription{address=cluster0-shard-00-00.e01hz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=372861730, setName='atlas-13mede-shard-0', canonicalAddress=cluster0-shard-00-00.e01hz.mongodb.net:27017, hosts=[cluster0-shard-00-00.e01hz.mongodb.net:27017, cluster0-shard-00-01.e01hz.mongodb.net:27017, cluster0-shard-00-02.e01hz.mongodb.net:27017], passives=[], arbiters=[], primary='cluster0-shard-00-02.e01hz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='GCP'}, Tag{name='region', value='WESTERN_EUROPE'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, topologyVersion=TopologyVersion{processId=62c56e83f53dd69119de57d2, counter=4}, lastWriteDate=Thu Jul 07 10:13:02 WEST 2022, lastUpdateTimeNanos=31272680687881}
2022-07-07 10:13:02,660 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-cluster0-shard-00-02.e01hz.mongodb.net:27017] Monitor thread successfully connected to server with description ServerDescription{address=cluster0-shard-00-02.e01hz.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=375547271, setName='atlas-13mede-shard-0', canonicalAddress=cluster0-shard-00-02.e01hz.mongodb.net:27017, hosts=[cluster0-shard-00-00.e01hz.mongodb.net:27017, cluster0-shard-00-01.e01hz.mongodb.net:27017, cluster0-shard-00-02.e01hz.mongodb.net:27017], passives=[], arbiters=[], primary='cluster0-shard-00-02.e01hz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='GCP'}, Tag{name='region', value='WESTERN_EUROPE'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff0000000000000264, setVersion=7, topologyVersion=TopologyVersion{processId=62c57003e8e029d9f95d58e7, counter=6}, lastWriteDate=Thu Jul 07 10:13:02 WEST 2022, lastUpdateTimeNanos=31272680624530}
2022-07-07 10:13:02,666 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-cluster0-shard-00-02.e01hz.mongodb.net:27017] Setting max election id to 7fffffff0000000000000264 from replica set primary cluster0-shard-00-02.e01hz.mongodb.net:27017
2022-07-07 10:13:02,667 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-cluster0-shard-00-02.e01hz.mongodb.net:27017] Setting max set version to 7 from replica set primary cluster0-shard-00-02.e01hz.mongodb.net:27017
2022-07-07 10:13:02,667 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62c6a39d4ee373315caf0bc3', description='null'}-cluster0-shard-00-02.e01hz.mongodb.net:27017] Discovered replica set primary cluster0-shard-00-02.e01hz.mongodb.net:27017
2022-07-07 10:13:02,674 WARN org.apache.kafka.clients.ClientUtils [restartedMain] Couldn't resolve server kafka:9092 from bootstrap.servers as DNS resolution failed for kafka
2022-07-07 10:13:02,675 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-07-07 10:13:02,675 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-07 10:13:02,675 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-07-07 10:13:02,677 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-example-1 unregistered
2022-07-07 10:13:02,678 WARN org.springframework.context.support.AbstractApplicationContext [restartedMain] Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'; nested exception is org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
2022-07-07 10:13:04,753 INFO org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener [restartedMain] 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2022-07-07 10:13:04,780 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'; nested exception is org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:181)
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:935)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:586)
	at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.refresh(ReactiveWebServerApplicationContext.java:66)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at academy.mindswap.restfulwebservice.RestfulWebServiceApplication.main(RestfulWebServiceApplication.java:17)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:823)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:664)
	at org.springframework.kafka.core.DefaultKafkaConsumerFactory.createRawConsumer(DefaultKafkaConsumerFactory.java:416)
	at org.springframework.kafka.core.DefaultKafkaConsumerFactory.createKafkaConsumer(DefaultKafkaConsumerFactory.java:384)
	at org.springframework.kafka.core.DefaultKafkaConsumerFactory.createConsumerWithAdjustedProperties(DefaultKafkaConsumerFactory.java:360)
	at org.springframework.kafka.core.DefaultKafkaConsumerFactory.createKafkaConsumer(DefaultKafkaConsumerFactory.java:327)
	at org.springframework.kafka.core.DefaultKafkaConsumerFactory.createConsumer(DefaultKafkaConsumerFactory.java:304)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.<init>(KafkaMessageListenerContainer.java:773)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer.doStart(KafkaMessageListenerContainer.java:351)
	at org.springframework.kafka.listener.AbstractMessageListenerContainer.start(AbstractMessageListenerContainer.java:461)
	at org.springframework.kafka.listener.ConcurrentMessageListenerContainer.doStart(ConcurrentMessageListenerContainer.java:209)
	at org.springframework.kafka.listener.AbstractMessageListenerContainer.start(AbstractMessageListenerContainer.java:461)
	at org.springframework.kafka.config.KafkaListenerEndpointRegistry.startIfNecessary(KafkaListenerEndpointRegistry.java:331)
	at org.springframework.kafka.config.KafkaListenerEndpointRegistry.start(KafkaListenerEndpointRegistry.java:276)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178)
	... 19 common frames omitted
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:730)
	... 33 common frames omitted
